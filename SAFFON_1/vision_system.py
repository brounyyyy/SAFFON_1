"""
ë¹„ì „ ì‹œìŠ¤í…œ - ë‹¤ì¤‘ ì¹´ë©”ë¼ ë° ê°ì²´ íƒì§€
"""

import pybullet as p
import cv2
import numpy as np
import os

class VisionSystem:
    def __init__(self):
        self.camera_width = 640
        self.camera_height = 480
        self.camera_fov = 60
        self.camera_aspect = self.camera_width / self.camera_height
        self.camera_near = 0.1
        self.camera_far = 3.0
        
        # ë‹¤ì¤‘ ì¹´ë©”ë¼ ì„¤ì •
        self.setup_cameras()
        print("ë¹„ì „ ì‹œìŠ¤í…œ ì´ˆê¸°í™” ì™„ë£Œ")
    
    def setup_cameras(self):
        """ë‹¤ì¤‘ ì¹´ë©”ë¼ ìœ„ì¹˜ ì„¤ì •"""
        self.cameras = {
            'top_view': {
                'eye_pos': [0.5, 0, 1.8],      # ìœ„ì—ì„œ ë‚´ë ¤ë‹¤ë³´ëŠ” ë©”ì¸ ì¹´ë©”ë¼
                'target_pos': [0.5, 0, 0.65],
                'up_vector': [0, 1, 0],
                'description': 'ìƒë‹¨ ë·° (ë©”ì¸ ì¹´ë©”ë¼)'
            },
            'side_left': {
                'eye_pos': [0.2, 0.6, 1.2],   # ì™¼ìª½ì—ì„œ ë³´ëŠ” ì¹´ë©”ë¼
                'target_pos': [0.5, 0, 0.65],
                'up_vector': [0, 0, 1],
                'description': 'ì¢Œì¸¡ ë·°'
            },
            'side_right': {
                'eye_pos': [0.2, -0.6, 1.2],  # ì˜¤ë¥¸ìª½ì—ì„œ ë³´ëŠ” ì¹´ë©”ë¼
                'target_pos': [0.5, 0, 0.65],
                'up_vector': [0, 0, 1],
                'description': 'ìš°ì¸¡ ë·°'
            },
            'front_view': {
                'eye_pos': [0.9, 0, 1.0],     # ì•ìª½ì—ì„œ ë³´ëŠ” ì¹´ë©”ë¼
                'target_pos': [0.5, 0, 0.65],
                'up_vector': [0, 0, 1],
                'description': 'ì „ë©´ ë·°'
            },
            'robot1_view': {
                'eye_pos': [-0.1, 0.5, 1.0],  # ë¡œë´‡1 ê´€ì 
                'target_pos': [0.5, 0, 0.65],
                'up_vector': [0, 0, 1],
                'description': 'ë¡œë´‡1 ê´€ì '
            },
            'robot2_view': {
                'eye_pos': [-0.1, -0.5, 1.0], # ë¡œë´‡2 ê´€ì 
                'target_pos': [0.5, 0, 0.65],
                'up_vector': [0, 0, 1],
                'description': 'ë¡œë´‡2 ê´€ì '
            }
        }
        
        print(f"{len(self.cameras)}ê°œ ì¹´ë©”ë¼ ì„¤ì • ì™„ë£Œ")
    
    def get_camera_image(self, camera_name='top_view'):
        """íŠ¹ì • ì¹´ë©”ë¼ì—ì„œ ì´ë¯¸ì§€ íšë“"""
        if camera_name not in self.cameras:
            print(f"ì¡´ì¬í•˜ì§€ ì•ŠëŠ” ì¹´ë©”ë¼: {camera_name}")
            return None, None, None
            
        camera = self.cameras[camera_name]
        
        try:
            view_matrix = p.computeViewMatrix(
                camera['eye_pos'], 
                camera['target_pos'], 
                camera['up_vector']
            )
            
            projection_matrix = p.computeProjectionMatrixFOV(
                self.camera_fov,
                self.camera_aspect,
                self.camera_near,
                self.camera_far
            )
            
            camera_data = p.getCameraImage(
                self.camera_width, 
                self.camera_height, 
                viewMatrix=view_matrix, 
                projectionMatrix=projection_matrix
            )
            
            width, height, rgbPixels, depthPixels, segmentationMaskBuffer = camera_data
            
            # RGB ì´ë¯¸ì§€ë¥¼ OpenCV í˜•ì‹ìœ¼ë¡œ ë³€í™˜
            rgb_array = np.array(rgbPixels, dtype=np.uint8).reshape(height, width, 4)
            rgb_array = rgb_array[:, :, :3]  # RGBAì—ì„œ RGBë¡œ
            
            return rgb_array, depthPixels, segmentationMaskBuffer
            
        except Exception as e:
            print(f"ì¹´ë©”ë¼ {camera_name} ì´ë¯¸ì§€ íšë“ ì˜¤ë¥˜: {e}")
            return None, None, None
    
    def get_all_camera_images(self):
        """ëª¨ë“  ì¹´ë©”ë¼ì—ì„œ ì´ë¯¸ì§€ íšë“"""
        all_images = {}
        for camera_name in self.cameras.keys():
            rgb_img, depth_img, seg_img = self.get_camera_image(camera_name)
            if rgb_img is not None:
                all_images[camera_name] = {
                    'rgb': rgb_img,
                    'depth': depth_img,
                    'segmentation': seg_img
                }
        return all_images
    
    def detect_purple_objects(self, rgb_image):
        """ë³´ë¼ìƒ‰ ê°ì²´ íƒì§€ (ìƒ‰ìƒ ê¸°ë°˜)"""
        try:
            # ì´ë¯¸ì§€ ë°ì´í„° íƒ€ì… í™•ì¸ ë° ë³€í™˜
            if rgb_image.dtype != np.uint8:
                rgb_image = rgb_image.astype(np.uint8)
            
            # BGRë¡œ ë³€í™˜ (OpenCV ì‚¬ìš©)
            bgr_image = cv2.cvtColor(rgb_image, cv2.COLOR_RGB2BGR)
            hsv_image = cv2.cvtColor(bgr_image, cv2.COLOR_BGR2HSV)
            
            # ë³´ë¼ìƒ‰ ë²”ìœ„ ì •ì˜ (ë” ë„“ì€ ë²”ìœ„)
            lower_purple1 = np.array([120, 50, 50])
            upper_purple1 = np.array([150, 255, 255])
            
            # ë³´ë¼ìƒ‰ ë²”ìœ„ 2 (ìì£¼ìƒ‰ ê³„ì—´)
            lower_purple2 = np.array([140, 30, 30])
            upper_purple2 = np.array([170, 255, 255])
            
            # ë‘ ë²”ìœ„ì˜ ë§ˆìŠ¤í¬ ìƒì„±
            mask1 = cv2.inRange(hsv_image, lower_purple1, upper_purple1)
            mask2 = cv2.inRange(hsv_image, lower_purple2, upper_purple2)
            mask = cv2.bitwise_or(mask1, mask2)
            
            # ë…¸ì´ì¦ˆ ì œê±°
            kernel = np.ones((3,3), np.uint8)
            mask = cv2.morphologyEx(mask, cv2.MORPH_OPEN, kernel)
            mask = cv2.morphologyEx(mask, cv2.MORPH_CLOSE, kernel)
            
            # ì»¨íˆ¬ì–´ ì°¾ê¸°
            contours, _ = cv2.findContours(mask, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)
            
            detected_objects = []
            for contour in contours:
                area = cv2.contourArea(contour)
                if area > 50:  # ìµœì†Œ ë©´ì  í•„í„° (ë” ì‘ì€ ê°’)
                    # ê°ì²´ ì¤‘ì‹¬ì  ê³„ì‚°
                    M = cv2.moments(contour)
                    if M["m00"] != 0:
                        cx = int(M["m10"] / M["m00"])
                        cy = int(M["m01"] / M["m00"])
                        detected_objects.append({
                            'center': (cx, cy),
                            'area': area,
                            'contour': contour
                        })
                        
            return detected_objects, mask
            
        except Exception as e:
            print(f"ìƒ‰ìƒ íƒì§€ ì˜¤ë¥˜: {e}")
            return [], None
    
    def detect_objects_multi_camera(self, target_objects=None):
        """ë‹¤ì¤‘ ì¹´ë©”ë¼ë¥¼ ì‚¬ìš©í•œ ê°ì²´ íƒì§€"""
        all_detections = {}
        
        for camera_name in self.cameras.keys():
            rgb_img, depth_img, seg_img = self.get_camera_image(camera_name)
            
            if rgb_img is not None:
                detected_objects, mask = self.detect_purple_objects(rgb_img)
                
                if detected_objects:
                    print(f"ğŸ“· {camera_name}: {len(detected_objects)}ê°œ ê°ì²´ íƒì§€")
                    all_detections[camera_name] = {
                        'objects': detected_objects,
                        'mask': mask,
                        'depth': depth_img,
                        'rgb': rgb_img
                    }
        
        return all_detections
    
    def find_best_detection(self, all_detections):
        """ê°€ì¥ ì¢‹ì€ íƒì§€ ê²°ê³¼ ì„ íƒ"""
        best_camera = None
        best_detection = None
        max_score = 0
        
        for camera_name, detection in all_detections.items():
            # ì ìˆ˜ ê³„ì‚°: ê°ì²´ ìˆ˜ + ë©´ì  ê¸°ì¤€
            objects = detection['objects']
            if objects:
                total_area = sum(obj['area'] for obj in objects)
                score = len(objects) * 100 + total_area  # ê°ì²´ ìˆ˜ë¥¼ ë” ì¤‘ìš”í•˜ê²Œ
                
                if score > max_score:
                    max_score = score
                    best_camera = camera_name
                    best_detection = detection
        
        if best_detection:
            print(f"ìµœì  ì¹´ë©”ë¼: {best_camera} (ì ìˆ˜: {max_score})")
            return best_camera, best_detection
        
        return None, None
    
    def pixel_to_world_coordinates(self, pixel_x, pixel_y, camera_name='top_view', depth_value=None):
        """í”½ì…€ ì¢Œí‘œë¥¼ ì›”ë“œ ì¢Œí‘œë¡œ ë³€í™˜"""
        try:
            # ì¹´ë©”ë¼ë³„ ë³€í™˜ íŒŒë¼ë¯¸í„° (ê°„ë‹¨í•œ ê·¼ì‚¬)
            if camera_name == 'top_view':
                # ìœ„ì—ì„œ ë‚´ë ¤ë‹¤ë³´ëŠ” ì¹´ë©”ë¼ì˜ ë³€í™˜
                norm_x = (pixel_x - self.camera_width/2) / (self.camera_width/2)
                norm_y = (pixel_y - self.camera_height/2) / (self.camera_height/2)
                
                # í…Œì´ë¸” ìœ„ì˜ ëŒ€ëµì ì¸ ì›”ë“œ ì¢Œí‘œë¡œ ë³€í™˜
                world_x = 0.5 + norm_x * 0.3  # í…Œì´ë¸” ë²”ìœ„ì— ë§ê²Œ ìŠ¤ì¼€ì¼ë§
                world_y = -norm_y * 0.3       # Yì¶• ë°˜ì „
                world_z = 0.70  # í…Œì´ë¸” ë†’ì´ + ê°ì²´ ë†’ì´
                
            else:
                # ë‹¤ë¥¸ ì¹´ë©”ë¼ë“¤ì— ëŒ€í•œ ê·¼ì‚¬ ë³€í™˜
                norm_x = (pixel_x - self.camera_width/2) / (self.camera_width/2)
                norm_y = (pixel_y - self.camera_height/2) / (self.camera_height/2)
                
                world_x = 0.5 + norm_x * 0.25
                world_y = norm_y * 0.25
                world_z = 0.70
            
            return [world_x, world_y, world_z]
            
        except Exception as e:
            print(f"ì¢Œí‘œ ë³€í™˜ ì˜¤ë¥˜: {e}")
            return [0.5, 0, 0.7]  # ê¸°ë³¸ê°’ ë°˜í™˜
    
    def save_camera_image(self, camera_name, rgb_image, detected_objects=None, save_dir="camera_images"):
        """ì¹´ë©”ë¼ ì´ë¯¸ì§€ ì €ì¥"""
        try:
            # ì €ì¥ ë””ë ‰í† ë¦¬ ìƒì„±
            if not os.path.exists(save_dir):
                os.makedirs(save_dir)
            
            # ì›ë³¸ ì´ë¯¸ì§€ ì €ì¥
            filename = os.path.join(save_dir, f"{camera_name}_original.png")
            cv2.imwrite(filename, cv2.cvtColor(rgb_image, cv2.COLOR_RGB2BGR))
            
            # íƒì§€ ê²°ê³¼ê°€ ìˆìœ¼ë©´ í‘œì‹œí•˜ì—¬ ì €ì¥
            if detected_objects:
                result_img = rgb_image.copy()
                
                for i, obj in enumerate(detected_objects):
                    center = obj['center']
                    area = obj['area']
                    
                    # ì¤‘ì‹¬ì ì— ì› ê·¸ë¦¬ê¸°
                    cv2.circle(result_img, center, 8, (0, 255, 0), 2)
                    
                    # í…ìŠ¤íŠ¸ ì¶”ê°€
                    text = f"{i+1}({area})"
                    cv2.putText(result_img, text, 
                              (center[0] + 10, center[1] - 10),
                              cv2.FONT_HERSHEY_SIMPLEX, 0.5, (0, 255, 0), 1)
                    
                    # ì»¨íˆ¬ì–´ ê·¸ë¦¬ê¸°
                    cv2.drawContours(result_img, [obj['contour']], -1, (255, 0, 0), 2)
                
                detection_filename = os.path.join(save_dir, f"{camera_name}_detection.png")
                cv2.imwrite(detection_filename, cv2.cvtColor(result_img, cv2.COLOR_RGB2BGR))
                
                return filename, detection_filename
            
            return filename, None
            
        except Exception as e:
            print(f"{camera_name} ì´ë¯¸ì§€ ì €ì¥ ì‹¤íŒ¨: {e}")
            return None, None
    
    def save_all_camera_views(self, target_objects=None):
        """ëª¨ë“  ì¹´ë©”ë¼ ë·° ì €ì¥"""
        print("ëª¨ë“  ì¹´ë©”ë¼ ë·° ì €ì¥ ì¤‘...")
        
        save_dir = f"camera_images_{int(time.time())}"  # íƒ€ì„ìŠ¤íƒ¬í”„ í¬í•¨
        saved_files = []
        
        # ëª¨ë“  ì¹´ë©”ë¼ ì´ë¯¸ì§€ íšë“
        all_images = self.get_all_camera_images()
        
        for camera_name, images in all_images.items():
            try:
                # ê°ì²´ íƒì§€ ìˆ˜í–‰
                detected_objects, mask = self.detect_purple_objects(images['rgb'])
                
                # ì´ë¯¸ì§€ ì €ì¥
                original_file, detection_file = self.save_camera_image(
                    camera_name, images['rgb'], detected_objects, save_dir)
                
                if original_file:
                    saved_files.append(original_file)
                    print(f"   {camera_name}: {original_file}")
                    
                    if detection_file:
                        saved_files.append(detection_file)
                        print(f"      íƒì§€ ê²°ê³¼: {len(detected_objects)}ê°œ ê°ì²´")
                
                # ë§ˆìŠ¤í¬ ì´ë¯¸ì§€ë„ ì €ì¥
                if mask is not None:
                    mask_filename = os.path.join(save_dir, f"{camera_name}_mask.png")
                    cv2.imwrite(mask_filename, mask)
                    saved_files.append(mask_filename)
                    
            except Exception as e:
                print(f"   {camera_name} ì²˜ë¦¬ ì‹¤íŒ¨: {e}")
                continue
        
        print(f"ì´ {len(saved_files)}ê°œ íŒŒì¼ ì €ì¥ ì™„ë£Œ")
        print(f"ì €ì¥ ìœ„ì¹˜: {save_dir}/")
        
        return saved_files
    
    def analyze_scene(self, target_objects=None):
        """ì „ì²´ ì¥ë©´ ë¶„ì„"""
        print("ì¥ë©´ ë¶„ì„ ì¤‘...")
        
        # ë‹¤ì¤‘ ì¹´ë©”ë¼ íƒì§€
        all_detections = self.detect_objects_multi_camera(target_objects)
        
        if not all_detections:
            print("ê°ì²´ë¥¼ íƒì§€í•˜ì§€ ëª»í–ˆìŠµë‹ˆë‹¤.")
            return None
        
        # ìµœì  íƒì§€ ê²°ê³¼ ì„ íƒ
        best_camera, best_detection = self.find_best_detection(all_detections)
        
        if not best_detection:
            print("ìœ íš¨í•œ íƒì§€ ê²°ê³¼ê°€ ì—†ìŠµë‹ˆë‹¤.")
            return None
        
        # ì›”ë“œ ì¢Œí‘œë¡œ ë³€í™˜
        world_positions = []
        for obj in best_detection['objects']:
            pixel_x, pixel_y = obj['center']
            world_pos = self.pixel_to_world_coordinates(pixel_x, pixel_y, best_camera)
            world_positions.append({
                'world_pos': world_pos,
                'pixel_pos': (pixel_x, pixel_y),
                'area': obj['area'],
                'camera': best_camera
            })
        
        analysis_result = {
            'best_camera': best_camera,
            'detected_count': len(world_positions),
            'world_positions': world_positions,
            'raw_detection': best_detection
        }
        
        print(f"ì¥ë©´ ë¶„ì„ ì™„ë£Œ:")
        print(f"   ìµœì  ì¹´ë©”ë¼: {best_camera}")
        print(f"   íƒì§€ëœ ê°ì²´: {len(world_positions)}ê°œ")
        
        return analysis_result
    
    def get_camera_info(self):
        """ì¹´ë©”ë¼ ì •ë³´ ì¶œë ¥"""
        print("ì¹´ë©”ë¼ ì‹œìŠ¤í…œ ì •ë³´:")
        print(f"   í•´ìƒë„: {self.camera_width}Ã—{self.camera_height}")
        print(f"   FOV: {self.camera_fov}Â°")
        print(f"   ì¹´ë©”ë¼ ìˆ˜: {len(self.cameras)}ê°œ")
        
        for name, camera in self.cameras.items():
            print(f"   {name}: {camera['description']}")
            print(f"      ìœ„ì¹˜: {camera['eye_pos']}")
            print(f"      íƒ€ê²Ÿ: {camera['target_pos']}")


import time
